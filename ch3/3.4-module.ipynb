{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.act(self.hidden(x))\n",
    "        return self.output(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "tensor([[ 0.0359,  0.5077,  0.2475,  0.2759, -0.0408,  0.1040, -0.0623, -0.0326,\n",
      "          0.0038,  0.2356],\n",
      "        [ 0.2110,  0.2071, -0.1685, -0.0423, -0.0872,  0.4703,  0.0632,  0.0918,\n",
      "          0.0154,  0.3298]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = MLP()\n",
    "X = torch.randn((2, 784))\n",
    "print(net)\n",
    "print(net(X)) # Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 4.])\n",
      "tensor([-2.,  0.,  2.])\n"
     ]
    }
   ],
   "source": [
    "# This is a layer to show  in forward() has no args inside\n",
    "class MinusMean(nn.Module):\n",
    "    def __init__(self, **kargs):\n",
    "        super(MinusMean, self).__init__(**kargs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean()\n",
    "        return x - mean\n",
    "\n",
    "net = MinusMean()\n",
    "X = torch.arange(0, 6, 2, dtype=torch.float32)\n",
    "print(X)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParamLayer(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (1): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (2): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (3): Parameter containing: [torch.float32 of size 4x1]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# This class is to show is there are model parameters\n",
    "class ParamLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ParamLayer, self).__init__(**kwargs)\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        #                                            创建一个 4x4 的随机矩阵 重复3次\n",
    "        #              创建成paramList\n",
    "        # params : []Parameters = {<4x4>, <4x4>, <4x4>}\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "        # params : []Parameters = {<4x4>, <4x4>, <4x4>, <4x1>}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            x = torch.mm(x, self.params[i]) # mm(mtx, mtx) -> 相乘\n",
    "        return x\n",
    "net = ParamLayer()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictLayer(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 下面的例子，给出了使用字典的实现\n",
    "class DictLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DictLayer, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "                'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "                'linear2': nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        # paramts = {\n",
    "        #     'linear1': <4, 4>,\n",
    "        #     'linear2': <4, 1>   \n",
    "        # }\n",
    "        self.params.update({'linear3': nn.Parameter(torch.randn(4, 2))})\n",
    "        # paramts = {\n",
    "        #     'linear1': <4, 4>,\n",
    "        #     'linear2': <4, 1>,\n",
    "        #     'linear3': <4, 2>\n",
    "        # }\n",
    "\n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])\n",
    "\n",
    "net = DictLayer()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D\n",
    "\n",
    "Cross-correlation layer\n",
    "\n",
    "![image.png](img/corr2d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2维 卷积层\n",
    "\n",
    "# 互相关操作（Cross-correlation）\n",
    "# X 为输入，K 为 Kernel\n",
    "def corr2d(X, K):\n",
    "    kern_h, kern_w = K.shape\n",
    "    X, K = X.float(), K.float()\n",
    "    \n",
    "    x_h, x_w = X.shape\n",
    "    Y = torch.zeros(x_h-kern_h+1, x_w-kern_w+1) # step 为 1 时，是这样的\n",
    "    for i in range(Y.shape[0]): # 根据 Y 的高进行循环\n",
    "        for j in range(Y.shape[1]): # 根据 Y 的宽进行循环\n",
    "            Y[i, j] = (X[i:i+kern_h, j:j+kern_w] * K).sum() # 如图进行\n",
    "    return Y\n",
    "\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kern_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kern_size))\n",
    "        self.bias = nn.Parameter(torch.rand(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([[0.8524, 0.8213, 0.8802, 0.9012, 0.8227, 0.8512, 0.2370, 0.8938],\n",
      "        [0.8969, 0.3820, 0.4716, 0.5227, 0.4212, 0.1732, 0.3654, 0.5197],\n",
      "        [0.2489, 0.3316, 0.9528, 0.4103, 0.8053, 0.7263, 0.6859, 0.2286],\n",
      "        [0.1610, 0.7672, 0.9025, 0.6521, 0.7532, 0.8518, 0.1074, 0.1946],\n",
      "        [0.1487, 0.1424, 0.1636, 0.0298, 0.8794, 0.1225, 0.1049, 0.1791],\n",
      "        [0.9035, 0.9541, 0.1282, 0.3487, 0.0459, 0.3504, 0.9695, 0.7530],\n",
      "        [0.9452, 0.1585, 0.7824, 0.3253, 0.4599, 0.8345, 0.6125, 0.1951],\n",
      "        [0.0355, 0.0646, 0.2585, 0.0912, 0.4140, 0.2836, 0.4103, 0.2219]])\n",
      "X_shape = torch.Size([8, 8])\n",
      "X_shape_added = (1, 1, 8, 8)\n",
      "X_V = tensor([[[[0.8524, 0.8213, 0.8802, 0.9012, 0.8227, 0.8512, 0.2370, 0.8938],\n",
      "          [0.8969, 0.3820, 0.4716, 0.5227, 0.4212, 0.1732, 0.3654, 0.5197],\n",
      "          [0.2489, 0.3316, 0.9528, 0.4103, 0.8053, 0.7263, 0.6859, 0.2286],\n",
      "          [0.1610, 0.7672, 0.9025, 0.6521, 0.7532, 0.8518, 0.1074, 0.1946],\n",
      "          [0.1487, 0.1424, 0.1636, 0.0298, 0.8794, 0.1225, 0.1049, 0.1791],\n",
      "          [0.9035, 0.9541, 0.1282, 0.3487, 0.0459, 0.3504, 0.9695, 0.7530],\n",
      "          [0.9452, 0.1585, 0.7824, 0.3253, 0.4599, 0.8345, 0.6125, 0.1951],\n",
      "          [0.0355, 0.0646, 0.2585, 0.0912, 0.4140, 0.2836, 0.4103, 0.2219]]]])\n",
      "Y = tensor([[[[-0.7241, -0.3537, -0.4433, -0.4097, -0.3852, -0.2109, -0.3741,\n",
      "           -0.3548],\n",
      "          [-0.3472, -0.0610, -0.2887, -0.0735, -0.1284, -0.0780, -0.4029,\n",
      "            0.0317],\n",
      "          [-0.2077, -0.4998, -0.3580, -0.1825, -0.3798, -0.3595, -0.0930,\n",
      "           -0.0102],\n",
      "          [-0.4810, -0.5343, -0.1465, -0.2204, -0.3921,  0.0356,  0.0490,\n",
      "           -0.2010],\n",
      "          [-0.4739, -0.2097,  0.0384, -0.3655, -0.1968,  0.0901, -0.3634,\n",
      "           -0.2287],\n",
      "          [-0.7471, -0.0771, -0.2161, -0.2988, -0.1062, -0.5768, -0.4798,\n",
      "           -0.0387],\n",
      "          [-0.2568, -0.0130, -0.3905, -0.1402, -0.5215, -0.3880, -0.0168,\n",
      "            0.0897],\n",
      "          [-0.0691, -0.3161, -0.1296, -0.2514, -0.2995, -0.1288, -0.1343,\n",
      "           -0.1270]]]], grad_fn=<ConvolutionBackward0>)\n",
      "Y_shape = torch.Size([1, 1, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    print(\"X =\", X)\n",
    "    print(\"X_shape =\", X.shape)\n",
    "    print(\"X_shape_added =\", (1, 1) + X.shape)\n",
    "    X = X.view((1, 1) + X.shape) # 8x8 -> 1x1x8x8\n",
    "    print(\"X_V =\", X)\n",
    "    Y = conv2d(X) # \n",
    "    print(\"Y =\", Y)\n",
    "    print(\"Y_shape =\", Y.shape)\n",
    "    return Y.view(Y.shape[2:])\n",
    "\n",
    "conv2dx = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1) # padding 是两侧的，因此是2行与2列\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "computed = comp_conv2d(conv2d=conv2dx, X=X)\n",
    "computed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([[0.8524, 0.8213, 0.8802, 0.9012, 0.8227, 0.8512, 0.2370, 0.8938],\n",
      "        [0.8969, 0.3820, 0.4716, 0.5227, 0.4212, 0.1732, 0.3654, 0.5197],\n",
      "        [0.2489, 0.3316, 0.9528, 0.4103, 0.8053, 0.7263, 0.6859, 0.2286],\n",
      "        [0.1610, 0.7672, 0.9025, 0.6521, 0.7532, 0.8518, 0.1074, 0.1946],\n",
      "        [0.1487, 0.1424, 0.1636, 0.0298, 0.8794, 0.1225, 0.1049, 0.1791],\n",
      "        [0.9035, 0.9541, 0.1282, 0.3487, 0.0459, 0.3504, 0.9695, 0.7530],\n",
      "        [0.9452, 0.1585, 0.7824, 0.3253, 0.4599, 0.8345, 0.6125, 0.1951],\n",
      "        [0.0355, 0.0646, 0.2585, 0.0912, 0.4140, 0.2836, 0.4103, 0.2219]])\n",
      "X_shape = torch.Size([8, 8])\n",
      "X_shape_added = (1, 1, 8, 8)\n",
      "X_V = tensor([[[[0.8524, 0.8213, 0.8802, 0.9012, 0.8227, 0.8512, 0.2370, 0.8938],\n",
      "          [0.8969, 0.3820, 0.4716, 0.5227, 0.4212, 0.1732, 0.3654, 0.5197],\n",
      "          [0.2489, 0.3316, 0.9528, 0.4103, 0.8053, 0.7263, 0.6859, 0.2286],\n",
      "          [0.1610, 0.7672, 0.9025, 0.6521, 0.7532, 0.8518, 0.1074, 0.1946],\n",
      "          [0.1487, 0.1424, 0.1636, 0.0298, 0.8794, 0.1225, 0.1049, 0.1791],\n",
      "          [0.9035, 0.9541, 0.1282, 0.3487, 0.0459, 0.3504, 0.9695, 0.7530],\n",
      "          [0.9452, 0.1585, 0.7824, 0.3253, 0.4599, 0.8345, 0.6125, 0.1951],\n",
      "          [0.0355, 0.0646, 0.2585, 0.0912, 0.4140, 0.2836, 0.4103, 0.2219]]]])\n",
      "Y = tensor([[[[ 0.0797,  0.2864,  0.2322,  0.1098,  0.1737,  0.1681,  0.0627,\n",
      "           -0.0673],\n",
      "          [ 0.1762,  0.0562, -0.1489,  0.0861, -0.0889,  0.0036, -0.3059,\n",
      "            0.0646],\n",
      "          [ 0.5421,  0.0509,  0.2038,  0.2514,  0.3582, -0.1587,  0.0666,\n",
      "            0.0205],\n",
      "          [ 0.5295,  0.0084,  0.0184,  0.0103, -0.2159,  0.0369,  0.0982,\n",
      "           -0.1166],\n",
      "          [ 0.2069,  0.0590,  0.3420, -0.2261,  0.3237,  0.1826, -0.1141,\n",
      "           -0.1373],\n",
      "          [ 0.1099,  0.4978,  0.0058,  0.1229,  0.4210,  0.0213,  0.0163,\n",
      "           -0.0335],\n",
      "          [ 0.0740, -0.1638, -0.2369,  0.1260,  0.1111, -0.1108, -0.1362,\n",
      "           -0.2216],\n",
      "          [ 0.3899, -0.2524, -0.1224, -0.1887, -0.1468,  0.0550,  0.0801,\n",
      "           -0.1979]]]], grad_fn=<ConvolutionBackward0>)\n",
      "Y_shape = torch.Size([1, 1, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用高为5、宽为3的卷积核。在⾼和宽两侧的填充数分别为2和1\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size # 或许池的大小\n",
    "    Y = torch.zeros((X.shape[0]-p_h+1, X.shape[1]-p_w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i:i+p_h, j:j+p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i:i+p_h, j:j+p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =\n",
      " tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "pool_max =\n",
      " tensor([[4., 5.],\n",
      "        [7., 8.]])\n",
      "pool_avg =\n",
      " tensor([[2., 3.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]], dtype=torch.float)\n",
    "print('X =\\n', X)\n",
    "Y = pool2d(X, (2, 2))\n",
    "print('pool_max =\\n', Y)\n",
    "Y = pool2d(X, (2, 2), 'avg')\n",
    "print('pool_avg =\\n', Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
